{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18f61a4e-a4d4-4e8e-a97a-a3b82c7b82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0cc25ae7-b229-476b-a558-b3b73439209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mle_elo(\n",
    "    df, SCALE=400, BASE=10, INIT_RATING=1000, sample_weight=None\n",
    "):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    ptbl_a_win = pd.pivot_table(\n",
    "        df[df[\"winner\"] == \"model_a\"],\n",
    "        index=\"model_a\",\n",
    "        columns=\"model_b\",\n",
    "        aggfunc=\"size\",\n",
    "        fill_value=0,\n",
    "    )\n",
    "    # if no tie, create a zero matrix\n",
    "    if sum(df[\"winner\"].isin([\"tie\", \"tie (bothbad)\"])) == 0:\n",
    "        ptbl_tie = pd.DataFrame(0, index=ptbl_a_win.index, columns=ptbl_a_win.columns)\n",
    "    else:\n",
    "        ptbl_tie = pd.pivot_table(\n",
    "            df[df[\"winner\"].isin([\"tie\", \"tie (bothbad)\"])],\n",
    "            index=\"model_a\",\n",
    "            columns=\"model_b\",\n",
    "            aggfunc=\"size\",\n",
    "            fill_value=0,\n",
    "        )\n",
    "        ptbl_tie = ptbl_tie + ptbl_tie.T\n",
    "\n",
    "    ptbl_b_win = pd.pivot_table(\n",
    "        df[df[\"winner\"] == \"model_b\"],\n",
    "        index=\"model_a\",\n",
    "        columns=\"model_b\",\n",
    "        aggfunc=\"size\",\n",
    "        fill_value=0,\n",
    "    )\n",
    "    ptbl_win = ptbl_a_win * 2 + ptbl_b_win.T * 2 + ptbl_tie\n",
    "\n",
    "    models = pd.Series(np.arange(len(ptbl_win.index)), index=ptbl_win.index)\n",
    "\n",
    "    p = len(models)\n",
    "    X = np.zeros([p * (p - 1) * 2, p])\n",
    "    Y = np.zeros(p * (p - 1) * 2)\n",
    "\n",
    "    cur_row = 0\n",
    "    sample_weights = []\n",
    "    for m_a in ptbl_win.index:\n",
    "        for m_b in ptbl_win.columns:\n",
    "            if m_a == m_b:\n",
    "                continue\n",
    "            # if nan skip\n",
    "            if math.isnan(ptbl_win.loc[m_a, m_b]) or math.isnan(ptbl_win.loc[m_b, m_a]):\n",
    "                continue\n",
    "            X[cur_row, models[m_a]] = +math.log(BASE)\n",
    "            X[cur_row, models[m_b]] = -math.log(BASE)\n",
    "            Y[cur_row] = 1.0\n",
    "            sample_weights.append(ptbl_win.loc[m_a, m_b])\n",
    "\n",
    "            X[cur_row + 1, models[m_a]] = math.log(BASE)\n",
    "            X[cur_row + 1, models[m_b]] = -math.log(BASE)\n",
    "            Y[cur_row + 1] = 0.0\n",
    "            sample_weights.append(ptbl_win.loc[m_b, m_a])\n",
    "            cur_row += 2\n",
    "    X = X[:cur_row]\n",
    "    Y = Y[:cur_row]\n",
    "\n",
    "    lr = LogisticRegression(fit_intercept=False, penalty=None, tol=1e-6)\n",
    "    lr.fit(X, Y, sample_weight=sample_weights)\n",
    "    elo_scores = SCALE * lr.coef_[0] + INIT_RATING\n",
    "    if \"mixtral-8x7b-instruct-v0.1\" in models.index:\n",
    "        elo_scores += 1114 - elo_scores[models[\"mixtral-8x7b-instruct-v0.1\"]]\n",
    "    return pd.Series(elo_scores, index=models.index).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0533fab0-2a16-40ab-bef7-2e19f284d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preety_print_model_ratings(ratings):\n",
    "    df = pd.DataFrame([\n",
    "        [n, ratings[n]] for n in ratings.keys()\n",
    "    ], columns=[\"Model\", \"Elo rating\"]).sort_values(\"Elo rating\", ascending=False).reset_index(drop=True)\n",
    "    # df[\"Elo rating\"] = (df[\"Elo rating\"] + 0.5).astype(int)\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "516fc1bc-b623-47bd-b800-7824d1d02bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/vh.json\", \"r\") as file:\n",
    "    vh = json.load(file)\n",
    "\n",
    "with open(\"voting_output/gpt-4o-2024-05-13_omni_bt_diff_acc_1.0_prob_dec_1.0_vote_num_4000.json\", \"r\") as file:\n",
    "    rigged = json.load(file)\n",
    "\n",
    "init_df = pd.DataFrame(list(vh.values()))\n",
    "\n",
    "modified_votes = list(vh.values()) + list(rigged.values())\n",
    "votes_df = pd.DataFrame(modified_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8dfb193-aefc-404c-b53a-7605be1d3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_elo_init = compute_mle_elo(init_df)\n",
    "mle_elo_rigged = compute_mle_elo(votes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "030f7c83-89f7-4057-9f28-7cf1e7220d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Elo rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatgpt-4o-latest</td>\n",
       "      <td>1314.763423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemini-1.5-pro-exp-0801</td>\n",
       "      <td>1297.837094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>1286.336146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>1275.656203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>1271.322521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>880.759889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>870.003972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>stablelm-tuned-alpha-7b</td>\n",
       "      <td>841.643041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td>819.238412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>llama-13b</td>\n",
       "      <td>800.598291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model   Elo rating\n",
       "1             chatgpt-4o-latest  1314.763423\n",
       "2       gemini-1.5-pro-exp-0801  1297.837094\n",
       "3             gpt-4o-2024-05-13  1286.336146\n",
       "4        gpt-4o-mini-2024-07-18  1275.656203\n",
       "5    claude-3-5-sonnet-20240620  1271.322521\n",
       "..                          ...          ...\n",
       "125                  chatglm-6b   880.759889\n",
       "126              fastchat-t5-3b   870.003972\n",
       "127     stablelm-tuned-alpha-7b   841.643041\n",
       "128                dolly-v2-12b   819.238412\n",
       "129                   llama-13b   800.598291\n",
       "\n",
       "[129 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_ranking_df = preety_print_model_ratings(mle_elo_init)\n",
    "init_ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "098ec6fd-c9c6-4b1b-ba27-3f533f718338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.500947820867623"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_ranking_df.iloc[2][\"Elo rating\"] - init_ranking_df.iloc[1][\"Elo rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db9c922e-4c30-4ae0-b392-699ec5e3a12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Elo rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatgpt-4o-latest</td>\n",
       "      <td>1309.719766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemini-1.5-pro-exp-0801</td>\n",
       "      <td>1293.676252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>1285.098494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>1271.831831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>1269.305333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>885.953899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>874.594598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>stablelm-tuned-alpha-7b</td>\n",
       "      <td>848.266695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>dolly-v2-12b</td>\n",
       "      <td>824.870885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>llama-13b</td>\n",
       "      <td>806.910065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model   Elo rating\n",
       "1             chatgpt-4o-latest  1309.719766\n",
       "2       gemini-1.5-pro-exp-0801  1293.676252\n",
       "3             gpt-4o-2024-05-13  1285.098494\n",
       "4        gpt-4o-mini-2024-07-18  1271.831831\n",
       "5    claude-3-5-sonnet-20240620  1269.305333\n",
       "..                          ...          ...\n",
       "125                  chatglm-6b   885.953899\n",
       "126              fastchat-t5-3b   874.594598\n",
       "127     stablelm-tuned-alpha-7b   848.266695\n",
       "128                dolly-v2-12b   824.870885\n",
       "129                   llama-13b   806.910065\n",
       "\n",
       "[129 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rigged_ranking_df = preety_print_model_ratings(mle_elo_rigged)\n",
    "rigged_ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e0f2ace8-389a-4cea-a3f2-dc3c86332afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9231896281485206"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rigged_ranking_df.iloc[2][\"Elo rating\"] - rigged_ranking_df.iloc[1][\"Elo rating\"]) - (init_ranking_df.iloc[2][\"Elo rating\"] - init_ranking_df.iloc[1][\"Elo rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3fad9b79-2f01-4260-a6aa-2410acc9ed01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69756"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((init_df[\"model_a\"] == \"gpt-4o-2024-05-13\") | (init_df[\"model_b\"] == \"gpt-4o-2024-05-13\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0781e664-d210-4650-88ef-ff2fe5e309ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17731"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((init_df[\"model_a\"] == \"llama-2-13b-chat\") | (init_df[\"model_b\"] == \"llama-2-13b-chat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1de428b-03d3-45af-85b4-80f7a1d28d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18048"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((init_df[\"model_a\"] == \"gemini-1.5-pro-exp-0801\") | (init_df[\"model_b\"] == \"gemini-1.5-pro-exp-0801\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24564407-6f40-4857-b8c0-9733645a15d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13079"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((init_df[\"model_a\"] == \"chatgpt-4o-latest\") | (init_df[\"model_b\"] == \"chatgpt-4o-latest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145935c-2392-4d5d-8b46-4df014bb8a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
